{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ddChq0dTxEz8"
   },
   "source": [
    "# Web & Scraping\n",
    "\n",
    "Requires: urllib, requests, socket, re, lxml, io, bs4, scrapy, sqlite3, pandas.\n",
    "\n",
    "План:\n",
    "* 101 101\n",
    "* HTML 101\n",
    "* HTTP + REST 101\n",
    "* Web scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "QIfo_au8xE0D"
   },
   "outputs": [],
   "source": [
    "# Убедитесь, что вот это вот всё установлено\n",
    "import urllib, requests, socket, re, lxml, io, bs4, scrapy, sqlite3, pandas, sqlalchemy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "jcCV1fKJxE0G"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml in c:\\users\\roshi\\anaconda3\\lib\\site-packages (4.6.3)\n",
      "Collecting bs4\n",
      "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
      "Collecting scrapy\n",
      "  Downloading Scrapy-2.7.1-py2.py3-none-any.whl (271 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\roshi\\anaconda3\\lib\\site-packages (1.3.4)\n",
      "Requirement already satisfied: sqlalchemy in c:\\users\\roshi\\anaconda3\\lib\\site-packages (1.4.22)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\roshi\\anaconda3\\lib\\site-packages (from bs4) (4.10.0)\n",
      "Requirement already satisfied: pyOpenSSL>=21.0.0 in c:\\users\\roshi\\anaconda3\\lib\\site-packages (from scrapy) (21.0.0)\n",
      "Collecting tldextract\n",
      "  Downloading tldextract-3.4.0-py3-none-any.whl (93 kB)\n",
      "Collecting Twisted>=18.9.0\n",
      "  Downloading Twisted-22.10.0-py3-none-any.whl (3.1 MB)\n",
      "Collecting service-identity>=18.1.0\n",
      "  Downloading service_identity-21.1.0-py2.py3-none-any.whl (12 kB)\n",
      "Collecting cssselect>=0.9.1\n",
      "  Downloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: cryptography>=3.3 in c:\\users\\roshi\\anaconda3\\lib\\site-packages (from scrapy) (3.4.8)\n",
      "Collecting parsel>=1.5.0\n",
      "  Downloading parsel-1.7.0-py2.py3-none-any.whl (14 kB)\n",
      "Collecting protego>=0.1.15\n",
      "  Downloading Protego-0.2.1-py2.py3-none-any.whl (8.2 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\roshi\\anaconda3\\lib\\site-packages (from scrapy) (58.0.4)\n",
      "Collecting queuelib>=1.4.2\n",
      "  Downloading queuelib-1.6.2-py2.py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\roshi\\anaconda3\\lib\\site-packages (from scrapy) (21.0)\n",
      "Collecting PyDispatcher>=2.0.5\n",
      "  Downloading PyDispatcher-2.0.6.tar.gz (38 kB)\n",
      "Requirement already satisfied: zope.interface>=5.1.0 in c:\\users\\roshi\\anaconda3\\lib\\site-packages (from scrapy) (5.4.0)\n",
      "Collecting itemadapter>=0.1.0\n",
      "  Downloading itemadapter-0.7.0-py3-none-any.whl (10 kB)\n",
      "Collecting w3lib>=1.17.0\n",
      "  Downloading w3lib-2.1.0-py3-none-any.whl (21 kB)\n",
      "Collecting itemloaders>=1.0.1\n",
      "  Downloading itemloaders-1.0.6-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\roshi\\anaconda3\\lib\\site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\roshi\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\roshi\\anaconda3\\lib\\site-packages (from pandas) (1.20.3)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\roshi\\anaconda3\\lib\\site-packages (from sqlalchemy) (1.1.1)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\roshi\\anaconda3\\lib\\site-packages (from cryptography>=3.3->scrapy) (1.14.6)\n",
      "Requirement already satisfied: pycparser in c:\\users\\roshi\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=3.3->scrapy) (2.20)\n",
      "Collecting jmespath>=0.9.5\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: six in c:\\users\\roshi\\anaconda3\\lib\\site-packages (from protego>=0.1.15->scrapy) (1.16.0)\n",
      "Collecting pyasn1-modules\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\roshi\\anaconda3\\lib\\site-packages (from service-identity>=18.1.0->scrapy) (21.2.0)\n",
      "Collecting pyasn1\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting Automat>=0.8.0\n",
      "  Downloading Automat-22.10.0-py2.py3-none-any.whl (26 kB)\n",
      "Collecting twisted-iocpsupport<2,>=1.0.2\n",
      "  Downloading twisted_iocpsupport-1.0.2-cp39-cp39-win_amd64.whl (45 kB)\n",
      "Collecting hyperlink>=17.1.1\n",
      "  Downloading hyperlink-21.0.0-py2.py3-none-any.whl (74 kB)\n",
      "Collecting incremental>=21.3.0\n",
      "  Downloading incremental-22.10.0-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5 in c:\\users\\roshi\\anaconda3\\lib\\site-packages (from Twisted>=18.9.0->scrapy) (3.10.0.2)\n",
      "Collecting constantly>=15.1\n",
      "  Downloading constantly-15.1.0-py2.py3-none-any.whl (7.9 kB)\n",
      "Requirement already satisfied: idna>=2.5 in c:\\users\\roshi\\anaconda3\\lib\\site-packages (from hyperlink>=17.1.1->Twisted>=18.9.0->scrapy) (3.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\roshi\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (2.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\roshi\\anaconda3\\lib\\site-packages (from packaging->scrapy) (3.0.4)\n",
      "Collecting requests-file>=1.4\n",
      "  Downloading requests_file-1.5.1-py2.py3-none-any.whl (3.7 kB)\n",
      "Requirement already satisfied: requests>=2.1.0 in c:\\users\\roshi\\anaconda3\\lib\\site-packages (from tldextract->scrapy) (2.26.0)\n",
      "Requirement already satisfied: filelock>=3.0.8 in c:\\users\\roshi\\anaconda3\\lib\\site-packages (from tldextract->scrapy) (3.3.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\roshi\\anaconda3\\lib\\site-packages (from requests>=2.1.0->tldextract->scrapy) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\roshi\\anaconda3\\lib\\site-packages (from requests>=2.1.0->tldextract->scrapy) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\roshi\\anaconda3\\lib\\site-packages (from requests>=2.1.0->tldextract->scrapy) (2021.10.8)\n",
      "Building wheels for collected packages: bs4, PyDispatcher\n",
      "  Building wheel for bs4 (setup.py): started\n",
      "  Building wheel for bs4 (setup.py): finished with status 'done'\n",
      "  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1271 sha256=c9e1129ca01e3314413b47691299388635f7b145f3e1caff3a8c26340feecb70\n",
      "  Stored in directory: c:\\users\\roshi\\appdata\\local\\pip\\cache\\wheels\\73\\2b\\cb\\099980278a0c9a3e57ff1a89875ec07bfa0b6fcbebb9a8cad3\n",
      "  Building wheel for PyDispatcher (setup.py): started\n",
      "  Building wheel for PyDispatcher (setup.py): finished with status 'done'\n",
      "  Created wheel for PyDispatcher: filename=PyDispatcher-2.0.6-py3-none-any.whl size=13003 sha256=1ebc09afc12ab864ced956c2f761017dac526b15e76fc8150c2a8715b43f6a6d\n",
      "  Stored in directory: c:\\users\\roshi\\appdata\\local\\pip\\cache\\wheels\\19\\e8\\03\\1fcb54c93a645b7a82114904e490f3b8d914ef0850d26544f6\n",
      "Successfully built bs4 PyDispatcher\n",
      "Installing collected packages: w3lib, pyasn1, cssselect, twisted-iocpsupport, requests-file, pyasn1-modules, parsel, jmespath, itemadapter, incremental, hyperlink, constantly, Automat, Twisted, tldextract, service-identity, queuelib, PyDispatcher, protego, itemloaders, scrapy, bs4\n",
      "Successfully installed Automat-22.10.0 PyDispatcher-2.0.6 Twisted-22.10.0 bs4-0.0.1 constantly-15.1.0 cssselect-1.2.0 hyperlink-21.0.0 incremental-22.10.0 itemadapter-0.7.0 itemloaders-1.0.6 jmespath-1.0.1 parsel-1.7.0 protego-0.2.1 pyasn1-0.4.8 pyasn1-modules-0.2.8 queuelib-1.6.2 requests-file-1.5.1 scrapy-2.7.1 service-identity-21.1.0 tldextract-3.4.0 twisted-iocpsupport-1.0.2 w3lib-2.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install lxml bs4 scrapy pandas sqlalchemy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IPhyLQnmxE0H"
   },
   "source": [
    "Заметка на полях:\n",
    "# 101 101\n",
    "\n",
    "В американской системе образования курсы имеют индекс, например, [CS101](https://lagunita.stanford.edu/courses/Engineering/CS101/Summer2014/about).\n",
    "\n",
    "101 -- это вводный курс в какую-то тему, просто так повелось. Intro.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OPs5nrTKxE0J",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Интернет 101\n",
    "\n",
    "Что происходит, когда вы вбиваете в поисковике адрес и жмете Enter?\n",
    "\n",
    "URL:  \n",
    "`<схема>:[//[<логин>[:<пароль>]@]<хост>[:<порт>]][/<URL‐путь>][?<параметры>][#<якорь>]`  \n",
    "Например:  \n",
    "`https://pp.userapi.com/c834101/v834101778/13450d/9yxFBjsPxN8.jpg`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tRyPMKRwxE0K"
   },
   "source": [
    "Вы выступаете **клиентом**\n",
    "\n",
    "1. **DNS**: URL -> IP-адрес и порт **сервера** (87.240.129.71:443)\n",
    "2. **HTTP(S)**: IP + URL-путь + параметры -> **ресурс** (текст (в т.ч. *HTML-документ*), картинка, звук и т.д.)\n",
    "3. **Движок браузера** пытается отрисовать документ\n",
    "4. *Скорее всего*, внутри документа написано, что ему требуются еще какие-то ресурсы, у них есть URI, т.е. возвращаемся к п.1\n",
    "5. Пока все это происходит, (и после того, как произошло), выполняется **JavaScript**-код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hTCInszbxE0M"
   },
   "source": [
    "# HTML 101\n",
    "\n",
    "HyperText Markup Language\n",
    "\n",
    "HTML -- язык разметки, который используется для web-страниц.\n",
    "\n",
    "Это механизм для получения структурного текста, который понимают браузеры.\n",
    "\n",
    "Структура в тексте задаётся вложенными тегами, теги определяют то, как текст будет показан (отрендерен).\n",
    "\n",
    "Это тег: `<тег>`, теги бывают открывающими (`<тег>`) и закрывающими (`</тег>`).\n",
    "\n",
    "Пример HTML-разметки:\n",
    "\n",
    "```html\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "   <head>\n",
    "      <meta charset=\"utf-8\" />\n",
    "      <title>HTML Document</title>\n",
    "   </head>\n",
    "   <body>\n",
    "      <p> <!-- p -- это параграф, а в такие странные скобки заключается комментарий -->\n",
    "         <b>\n",
    "            Этот текст будет полужирным, <i>а этот — ещё и курсивным</i>.\n",
    "         </b>\n",
    "      </p>\n",
    "   </body>\n",
    "</html>\n",
    "```\n",
    "\n",
    "Так он выглядит после рендеринга:\n",
    "\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "   <head>\n",
    "      <meta charset=\"utf-8\" />\n",
    "      <title>HTML Document</title>\n",
    "   </head>\n",
    "   <body>\n",
    "      <p> <!-- p -- это параграф, а в такие странные скобки заключается комментарий -->\n",
    "         <b>\n",
    "            Этот текст будет полужирным, <i>а этот — ещё и курсивным</i>.\n",
    "         </b>\n",
    "      </p>\n",
    "   </body>\n",
    "</html>\n",
    "\n",
    "Видно, что HTML-разметка имеет древовидную структуру:<br>\n",
    "каждый тег (вершина дерева) имеет 0 (тогда это лист дерева) или больше (тогда это внутренняя вершина) вложенных в него тегов.\n",
    "\n",
    "Значит, чтобы доставать из HTML какую-то информацию, можно использовать его структуру.\n",
    "\n",
    "Мы этим займёмся чуть позже.\n",
    "\n",
    "### P.S. \n",
    "На самом деле, такую же структуру имеет и формат XML (другой язык разметки).\n",
    "\n",
    "Формально, HTML -- это более стандартизированное подмножество XML.\n",
    "\n",
    "### P.P.S.\n",
    "\n",
    "А ещё у тегов бывают **атрибуты**:\n",
    "\n",
    "```html\n",
    "<a href=\"http://example.com\">Ссылка на example.com</a>\n",
    "```\n",
    "Отрендерим этот кусок:\n",
    "<a href=\"http://example.com\">Ссылка на example.com</a>\n",
    "\n",
    "### P.P.P.S.\n",
    "\n",
    "А этот текст (безусловно, имеющий структуру), был написан с помощью другого языка разметки -- **Markdown**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pS4YGla2xE0P"
   },
   "source": [
    "## HTTP 101\n",
    "\n",
    "HyperText Transfer Protocol\n",
    "\n",
    "Протокол передачи гипертекста:\n",
    "* **Протокол** -- набор логических соглашений о взаимодействии программ, стандарт;\n",
    "* **передача** -- мы живём в интернете, т.е. мир не ограничивается нашим компьютером => информацию надо передавать;\n",
    "* **гипертекст** -- HTML, например.\n",
    "\n",
    "Основная идея: все компьютеры делятся на **сервера** (те, что хранят информацию) и **клиенты** (те, что запрашивают её).\n",
    "\n",
    "На самом деле, в HTTP мы передаём не только гипертекст, а **ресурсы** -- философское обобщение, куда попадает и гипертекст, и картинки, и музыка и т.д. Но стандарт подходит для всего этого.\n",
    "\n",
    "Каждый ресурс имеет адрес -- **URI** (Uniform Resource Identifier) -- аналог пути в системе компьютера.\n",
    "\n",
    "Не будем говорить про низкоуровневую сторону вопроса: стек TCP/IP, сокеты, порты и т.д.\n",
    "\n",
    "## Структура HTTP\n",
    "\n",
    "Чтобы получить данные, клиент делает запрос на сервер. В запросе должны быть 3 части:\n",
    "* Starting line -- определяет тип сообщения;\n",
    "* Headers -- характеризуют тело сообщения, параметры передачи и прочие сведения;\n",
    "* Message body -- непосредственно данные сообщения.\n",
    "\n",
    "Ответное сообщение от сервера имеет такую же структуру.\n",
    "\n",
    "Чтобы посылать эти запросы \"руками\", а не через браузер, можно использовать утилиту `curl`. Ей и воспользуемся."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "waEkxNUhxE0R"
   },
   "outputs": [],
   "source": [
    "!curl example.com/index.html -v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GmRaHPnRxE0T"
   },
   "source": [
    "## Методы HTTP\n",
    "\n",
    "HTTP метод определяет операцию, которую мы хотим произвести над ресурсом.\n",
    "\n",
    "Самые частые методы: GET, POST, PUT, DELETE (но есть и другие).\n",
    "\n",
    "* **GET** -- запрос содержимого ресурса. <br>GET-запросы идемпотентны. Поэтому они могут кэшироваться.\n",
    "* **POST** -- передача данных на ресурс (например, при отправке комментария на форуме или вводе пароля на сайте). <br> Не идемпотентны => при отправке одного и того же комментария на форум он появится там дважды.  <br>Не кэшируются.\n",
    "* **PUT** -- передача данных в конкретный URI (изменение существующего ресурса). Не кэшируются.\n",
    "* **DELETE** -- удаление ресурса.\n",
    "\n",
    "## Коды HTTP\n",
    "\n",
    "В ответном сообщении придёт код ответа HTTP, который определяет результат выполнения операции.\n",
    "\n",
    "Самые частые коды: `200 OK`, `400 BadRequest`, `404 Not Found`, `500 Internal Server Error`.\n",
    "\n",
    "Общий обзор кодов:\n",
    "* **1xx** -- Informational. Информационные коды, например, `102 Processing` (запрос пока обрабатывается);\n",
    "* **2xx** -- Success. Успех. Всё хорошо, запрос отработал и ничего не сломал. По крайней мере, пока.\n",
    "* **3xx** -- Redirection. Перенаправление на другой ресурс/страницу.\n",
    "* **4xx** -- Client error. Ошибка клиента (неверные данные запроса или неправильный путь).\n",
    "* **5xx** -- Server error. Что-то сломалось на сервере (там поделили на ноль, например)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TWBFz3I5xE0V"
   },
   "source": [
    "## Разбор примера\n",
    "\n",
    "Давайте ещё раз посмотрим на запрос к example.com/index.html.\n",
    "\n",
    "Служебная информация от `curl`:\n",
    "\n",
    "```\n",
    "*   Trying 2606:2800:220:1:248:1893:25c8:1946...\n",
    "*   Trying 93.184.216.34...\n",
    "* Connected to example.com (2606:2800:220:1:248:1893:25c8:1946) port 80 (#0)\n",
    "```\n",
    "Запрос клиента:\n",
    "```\n",
    "> GET /index.html HTTP/1.1    # Starting line: метод GET, URI -- /index.html, версия протокола -- HTTP/1.1\n",
    "> Host: example.com           # Заголовки сообщения\n",
    "> User-Agent: curl/7.47.0\n",
    "> Accept: */*\n",
    ">                             # Пустое тело, т.к. мы ничего не передали на сервер.\n",
    "```\n",
    "\n",
    "Ответ сервера:\n",
    "```\n",
    "< HTTP/1.1 200 OK                          # Starting line: версия протокола и код ответа\n",
    "< Cache-Control: max-age=604800            # Заголовки ответа\n",
    "< Content-Type: text/html; charset=UTF-8\n",
    "< Date: Tue, 19 Mar 2019 21:25:21 GMT\n",
    "< Etag: \"1541025663+gzip+ident\"\n",
    "< Expires: Tue, 26 Mar 2019 21:25:21 GMT\n",
    "< Last-Modified: Fri, 09 Aug 2013 23:54:35 GMT\n",
    "< Server: ECS (bsa/EB1E)\n",
    "< Vary: Accept-Encoding\n",
    "< X-Cache: HIT\n",
    "< Content-Length: 1270\n",
    "<                                          # Пустая строка -- нужна по стандарту\n",
    "<!doctype html>                            # Тело ответа -- HTML-документ\n",
    "<html>\n",
    "<head>\n",
    "    <title>Example Domain</title>\n",
    ". . .\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CA7AvKSlxE0X"
   },
   "source": [
    "## REST\n",
    "\n",
    " <a href=\"https://en.wikipedia.org/wiki/Representational_state_transfer\">Representational State Transfer</a> \n",
    "\n",
    "Набор дополнительных ограничений на HTTP, указывающий, как правильно работать с методами, кодами и т.д.\n",
    "\n",
    "Можно назвать его аналогом pep для Питона."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bA5J49omxE0Z"
   },
   "source": [
    "## https://faun.pub/http-and-everything-you-need-to-know-about-it-8273bc224491 - доступно про HTTP (english)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pBhYg97AxE0a"
   },
   "source": [
    "# Web scraping. Практика!\n",
    "\n",
    "* Получение html\n",
    "* Парсинг html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C0oQM0yGxE0b"
   },
   "source": [
    "## Получение html\n",
    "\n",
    "Варианты инструментов:\n",
    "\n",
    "* urllib \n",
    "* requests (de-facto standard)\n",
    "* socket (low-level)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d3zqNFJ5xE0c"
   },
   "source": [
    "### urllib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SXZar7-sxE0d"
   },
   "outputs": [],
   "source": [
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "6iJd8rCpxE0d",
    "outputId": "825f1b8f-d362-460e-d747-169963aebe4e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<!doctype html>\\n<html>\\n<head>\\n    <title>Example Domain</title>\\n\\n    <meta charset=\"utf-8\" />\\n    <meta http-equiv=\"Content-type\" content=\"text/html; charset=utf-8\" />\\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\\n    <style type=\"text/css\">\\n    body {\\n        background-color: #f0f0f2;\\n        margin: 0;\\n        padding: 0;\\n        font-family: -apple-system, system-ui, BlinkMacSystemFont, \"Segoe UI\", \"Open Sans\", \"Helvetica Neue\", Helvetica, Arial, sans-serif;\\n        \\n    }\\n    div {\\n        width: 600px;\\n        margin: 5em auto;\\n        padding: 2em;\\n        background-color: #fdfdff;\\n        border-radius: 0.5em;\\n        box-shadow: 2px 3px 7px 2px rgba(0,0,0,0.02);\\n    }\\n    a:link, a:visited {\\n        color: #38488f;\\n        text-decoration: none;\\n    }\\n    @media (max-width: 700px) {\\n        div {\\n            margin: 0 auto;\\n            width: auto;\\n        }\\n    }\\n    </style>    \\n</head>\\n\\n<body>\\n<div>\\n    <h1>Example Domain</h1>\\n    <p>This domain is for use in illustrative examples in documents. You may use this\\n    domain in literature without prior coordination or asking for permission.</p>\\n    <p><a href=\"https://www.iana.org/domains/example\">More information...</a></p>\\n</div>\\n</body>\\n</html>\\n'\n"
     ]
    }
   ],
   "source": [
    "response = urllib.request.urlopen('http://example.com/')\n",
    "html = response.read()\n",
    "print(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "v6Irf6cCxE0f",
    "outputId": "a7b11ad4-cf31-4cb9-f626-d214ba3edb16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!doctype html>\n",
      "<html>\n",
      "<head>\n",
      "    <title>Example Domain</title>\n",
      "\n",
      "    <meta charset=\"utf-8\" />\n",
      "    <meta http-equiv=\"Content-type\" content=\"text/html; charset=utf-8\" />\n",
      "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\n",
      "    <style type=\"text/css\">\n",
      "    body {\n",
      "        background-color: #f0f0f2;\n",
      "        margin: 0;\n",
      "        padding: 0;\n",
      "        font-family: -apple-system, system-ui, BlinkMacSystemFont, \"Segoe UI\", \"Open Sans\", \"Helvetica Neue\", Helvetica, Arial, sans-serif;\n",
      "        \n",
      "    }\n",
      "    div {\n",
      "        width: 600px;\n",
      "        margin: 5em auto;\n",
      "        padding: 2em;\n",
      "        background-color: #fdfdff;\n",
      "        border-radius: 0.5em;\n",
      "        box-shadow: 2px 3px 7px 2px rgba(0,0,0,0.02);\n",
      "    }\n",
      "    a:link, a:visited {\n",
      "        color: #38488f;\n",
      "        text-decoration: none;\n",
      "    }\n",
      "    @media (max-width: 700px) {\n",
      "        div {\n",
      "            margin: 0 auto;\n",
      "            width: auto;\n",
      "        }\n",
      "    }\n",
      "    </style>    \n",
      "</head>\n",
      "\n",
      "<body>\n",
      "<div>\n",
      "    <h1>Example Domain</h1>\n",
      "    <p>This domain is for use in illustrative examples in documents. You may use this\n",
      "    domain in literature without prior coordination or asking for permission.</p>\n",
      "    <p><a href=\"https://www.iana.org/domains/example\">More information...</a></p>\n",
      "</div>\n",
      "</body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "html = html.decode('utf-8')\n",
    "print(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S9fv57ezxE0g"
   },
   "source": [
    "На всякий случай сохраним этот html, пригодится."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "lykMosh5xE0i"
   },
   "outputs": [],
   "source": [
    "with open('example.com.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3VaQHI4_xE0j"
   },
   "source": [
    "А что, кроме html?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "oJQ5fFolxE0j",
    "outputId": "565f3298-e5b7-4187-8442-59b5dbfa6dea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__abstractmethods__', '__class__', '__del__', '__delattr__', '__dict__', '__dir__', '__doc__', '__enter__', '__eq__', '__exit__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__next__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '_abc_impl', '_checkClosed', '_checkReadable', '_checkSeekable', '_checkWritable', '_check_close', '_close_conn', '_get_chunk_left', '_method', '_peek_chunked', '_read1_chunked', '_read_and_discard_trailer', '_read_next_chunk_size', '_read_status', '_readall_chunked', '_readinto_chunked', '_safe_read', '_safe_readinto', 'begin', 'chunk_left', 'chunked', 'close', 'closed', 'code', 'debuglevel', 'detach', 'fileno', 'flush', 'fp', 'getcode', 'getheader', 'getheaders', 'geturl', 'headers', 'info', 'isatty', 'isclosed', 'length', 'msg', 'peek', 'read', 'read1', 'readable', 'readinto', 'readinto1', 'readline', 'readlines', 'reason', 'seek', 'seekable', 'status', 'tell', 'truncate', 'url', 'version', 'will_close', 'writable', 'write', 'writelines']\n"
     ]
    }
   ],
   "source": [
    "print(dir(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JCqo_C_zxE0l"
   },
   "source": [
    "Всё, что есть в HTTP-сообщении."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "HZ8ZqLWIxE0m",
    "outputId": "89d12e1b-7c15-49c3-8872-f8caf570ccb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://example.com/\n",
      "OK\n",
      "200\n",
      "Заголовки: \n",
      "Accept-Ranges: bytes\n",
      "Age: 580122\n",
      "Cache-Control: max-age=604800\n",
      "Content-Type: text/html; charset=UTF-8\n",
      "Date: Mon, 05 Dec 2022 10:14:58 GMT\n",
      "Etag: \"3147526947\"\n",
      "Expires: Mon, 12 Dec 2022 10:14:58 GMT\n",
      "Last-Modified: Thu, 17 Oct 2019 07:18:26 GMT\n",
      "Server: ECS (nyb/1D06)\n",
      "Vary: Accept-Encoding\n",
      "X-Cache: HIT\n",
      "Content-Length: 1256\n",
      "Connection: close\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response.url)\n",
    "print(response.msg)\n",
    "print(response.code)\n",
    "print('Заголовки: \\n{}'.format(response.headers))\n",
    "# . . ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G8O1vOSaxE0n"
   },
   "source": [
    "### requests\n",
    "HTTP for Humans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "TI1iWk5yxE0o"
   },
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "gXtfRKd_xE0p",
    "outputId": "0e94dee7-38dc-4caa-c35b-714f4ec3a356"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.get('http://example.com')\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "aNpjHkxYxE0q",
    "outputId": "103158a5-5e17-4e33-ca5f-8bb16901a3db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__attrs__', '__bool__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__enter__', '__eq__', '__exit__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__nonzero__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_content', '_content_consumed', '_next', 'apparent_encoding', 'close', 'connection', 'content', 'cookies', 'elapsed', 'encoding', 'headers', 'history', 'is_permanent_redirect', 'is_redirect', 'iter_content', 'iter_lines', 'json', 'links', 'next', 'ok', 'raise_for_status', 'raw', 'reason', 'request', 'status_code', 'text', 'url']\n"
     ]
    }
   ],
   "source": [
    "print(dir(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "O1lf8l8axE0q",
    "outputId": "f3dad984-9700-4d40-f130-310632c214c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://example.com/\n",
      "<requests.adapters.HTTPAdapter object at 0x0000028B1B607CA0>\n",
      "{'Content-Encoding': 'gzip', 'Accept-Ranges': 'bytes', 'Age': '297268', 'Cache-Control': 'max-age=604800', 'Content-Type': 'text/html; charset=UTF-8', 'Date': 'Mon, 05 Dec 2022 10:15:29 GMT', 'Etag': '\"3147526947\"', 'Expires': 'Mon, 12 Dec 2022 10:15:29 GMT', 'Last-Modified': 'Thu, 17 Oct 2019 07:18:26 GMT', 'Server': 'ECS (nyb/1D18)', 'Vary': 'Accept-Encoding', 'X-Cache': 'HIT', 'Content-Length': '648'}\n",
      "True\n",
      "200\n",
      "UTF-8\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "print(response.url)\n",
    "print(response.connection)\n",
    "print(response.headers)\n",
    "print(response.ok)\n",
    "print(response.status_code)\n",
    "print(response.encoding)\n",
    "print(response.links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "tjXVaRsuxE0r",
    "outputId": "7e6f69b1-6fcc-411d-e575-758ecd824129"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!doctype html>\n",
      "<html>\n",
      "<head>\n",
      "    <title>Example Domain</title>\n",
      "\n",
      "    <meta charset=\"utf-8\" />\n",
      "    <meta http-equiv=\"Content-type\" content=\"text/html; charset=utf-8\" />\n",
      "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\n",
      "    <style type=\"text/css\">\n",
      "    body {\n",
      "        background-color: #f0f0f2;\n",
      "        margin: 0;\n",
      "        padding: 0;\n",
      "        font-family: -apple-system, system-ui, BlinkMacSystemFont, \"Segoe UI\", \"Open Sans\", \"Helvetica Neue\", Helvetica, Arial, sans-serif;\n",
      "        \n",
      "    }\n",
      "    div {\n",
      "        width: 600px;\n",
      "        margin: 5em auto;\n",
      "        padding: 2em;\n",
      "        background-color: #fdfdff;\n",
      "        border-radius: 0.5em;\n",
      "        box-shadow: 2px 3px 7px 2px rgba(0,0,0,0.02);\n",
      "    }\n",
      "    a:link, a:visited {\n",
      "        color: #38488f;\n",
      "        text-decoration: none;\n",
      "    }\n",
      "    @media (max-width: 700px) {\n",
      "        div {\n",
      "            margin: 0 auto;\n",
      "            width: auto;\n",
      "        }\n",
      "    }\n",
      "    </style>    \n",
      "</head>\n",
      "\n",
      "<body>\n",
      "<div>\n",
      "    <h1>Example Domain</h1>\n",
      "    <p>This domain is for use in illustrative examples in documents. You may use this\n",
      "    domain in literature without prior coordination or asking for permission.</p>\n",
      "    <p><a href=\"https://www.iana.org/domains/example\">More information...</a></p>\n",
      "</div>\n",
      "</body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "53l5xXVAxE0s"
   },
   "source": [
    "### socket (low-level, если вам в жизни мало ассемблера)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "SLlpVPl0xE0s"
   },
   "outputs": [],
   "source": [
    "import socket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "S9UIvSULxE0t",
    "outputId": "b14feccf-c7b7-4c25-ec4e-bbfbd4481d30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP/1.1 200 OK\r\n",
      "Age: 346542\r\n",
      "Cache-Control: max-age=604800\r\n",
      "Content-Type: text/html; charset=UTF-8\r\n",
      "Date: Mon, 05 Dec 2022 10:15:47 GMT\r\n",
      "Etag: \"3147526947+ident\"\r\n",
      "Expires: Mon, 12 Dec 2022 10:15:47 GMT\r\n",
      "Last-Modified: Thu, 17 Oct 2019 07:18:26 GMT\r\n",
      "Server: ECS (nyb/1D2A)\r\n",
      "Vary: Accept-Encoding\r\n",
      "X-Cache: HIT\r\n",
      "Content-Length: 1256\r\n",
      "\r\n",
      "<!doctype html>\n",
      "<html>\n",
      "<head>\n",
      "    <title>Example Domain</title>\n",
      "\n",
      "    <meta charset=\"utf-8\" />\n",
      "    <meta http-equiv=\"Content-type\" content=\"text/html; charset=utf-8\" />\n",
      "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\n",
      "    <style type=\"text/css\">\n",
      "    body {\n",
      "        background-color: #f0f0f2;\n",
      "        margin: 0;\n",
      "        padding: 0;\n",
      "        font-family: -apple-system, system-ui, BlinkMacSystemFont, \"Segoe UI\", \"Open Sans\", \"Helvetica Neue\", Helvetica, Arial, sans-serif;\n",
      "        \n",
      "    }\n",
      "    div {\n",
      "        width: 600px;\n",
      "        margin: 5em auto;\n",
      "        padding: 2em;\n",
      "        background-color: #fdfdff;\n",
      "        border-radius: 0.5em;\n",
      "        box-shadow: 2px 3px 7px 2px rgba(0,0,0,0.02);\n",
      "    }\n",
      "    a:link, a:visited {\n",
      "        color: #38488f;\n",
      "        text-decoration: none;\n",
      "    }\n",
      "    @media (max-width: 700px) {\n",
      "        div {\n",
      "            margin: 0 auto;\n",
      "            width: auto;\n",
      "        }\n",
      "    }\n",
      "    </style>    \n",
      "</head>\n",
      "\n",
      "<body>\n",
      "<div>\n",
      "    <h1>Example Domain</h1>\n",
      "    <p>This domain is for use in illustrative examples in documents. You may use this\n",
      "    domain in literature without prior coordination or asking for permission.</p>\n",
      "    <p><a href=\"https://www.iana.org/domains/example\">More information...</a></p>\n",
      "</div>\n",
      "</body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "host = socket.gethostbyname('www.example.com')\n",
    "port = 80\n",
    "\n",
    "sock.connect((host,port))\n",
    "sock.sendall(b'GET / HTTP/1.1\\r\\nHost: www.example.com\\r\\n\\r\\n')\n",
    "\n",
    "val = sock.recv(4096)\n",
    "print(val.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mn51lOG8xE0t",
    "outputId": "24d2ac23-ad81-4fe6-f2c3-3757bd7e0763"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!doctype html>\n",
      "<html>\n",
      "<head>\n",
      "    <title>Example Domain</title>\n",
      "\n",
      "    <meta charset=\"utf-8\" />\n",
      "    <meta http-equiv=\"Content-type\" content=\"text/html; charset=utf-8\" />\n",
      "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\n",
      "    <style type=\"text/css\">\n",
      "    body {\n",
      "        background-color: #f0f0f2;\n",
      "        margin: 0;\n",
      "        padding: 0;\n",
      "        font-family: -apple-system, system-ui, BlinkMacSystemFont, \"Segoe UI\", \"Open Sans\", \"Helvetica Neue\", Helvetica, Arial, sans-serif;\n",
      "        \n",
      "    }\n",
      "    div {\n",
      "        width: 600px;\n",
      "        margin: 5em auto;\n",
      "        padding: 2em;\n",
      "        background-color: #fdfdff;\n",
      "        border-radius: 0.5em;\n",
      "        box-shadow: 2px 3px 7px 2px rgba(0,0,0,0.02);\n",
      "    }\n",
      "    a:link, a:visited {\n",
      "        color: #38488f;\n",
      "        text-decoration: none;\n",
      "    }\n",
      "    @media (max-width: 700px) {\n",
      "        div {\n",
      "            margin: 0 auto;\n",
      "            width: auto;\n",
      "        }\n",
      "    }\n",
      "    </style>    \n",
      "</head>\n",
      "\n",
      "<body>\n",
      "<div>\n",
      "    <h1>Example Domain</h1>\n",
      "    <p>This domain is for use in illustrative examples in documents. You may use this\n",
      "    domain in literature without prior coordination or asking for permission.</p>\n",
      "    <p><a href=\"https://www.iana.org/domains/example\">More information...</a></p>\n",
      "</div>\n",
      "</body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split off the HTTP headers\n",
    "val = val.split(b'\\r\\n\\r\\n',1)[1]\n",
    "print(val.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PI7XmjXRxE0u"
   },
   "source": [
    "## Парсинг html\n",
    "\n",
    "Варианты инструментов:\n",
    "* re\n",
    "* lxml\n",
    "* BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "VXFA9aK8xE0v",
    "outputId": "6ef30f5f-f3bf-4028-d093-630165fc9a49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!doctype html>\n",
      "<html>\n",
      "<head>\n",
      "    <title>Example Domain</title>\n",
      "\n",
      "    <meta charset=\"utf-8\" />\n",
      "    <meta http-equiv=\"Content-type\" content=\"text/html; charset=utf-8\" />\n",
      "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\n",
      "    <style type=\"text/css\">\n",
      "    body {\n",
      "        background-color: #f0f0f2;\n",
      "        margin: 0;\n",
      "        padding: 0;\n",
      "        font-family: -apple-system, system-ui, BlinkMacSystemFont, \"Segoe UI\", \"Open Sans\", \"Helvetica Neue\", Helvetica, Arial, sans-serif;\n",
      "        \n",
      "    }\n",
      "    div {\n",
      "        width: 600px;\n",
      "        margin: 5em auto;\n",
      "        padding: 2em;\n",
      "        background-color: #fdfdff;\n",
      "        border-radius: 0.5em;\n",
      "        box-shadow: 2px 3px 7px 2px rgba(0,0,0,0.02);\n",
      "    }\n",
      "    a:link, a:visited {\n",
      "        color: #38488f;\n",
      "        text-decoration: none;\n",
      "    }\n",
      "    @media (max-width: 700px) {\n",
      "        div {\n",
      "            margin: 0 auto;\n",
      "            width: auto;\n",
      "        }\n",
      "    }\n",
      "    </style>    \n",
      "</head>\n",
      "\n",
      "<body>\n",
      "<div>\n",
      "    <h1>Example Domain</h1>\n",
      "    <p>This domain is for use in illustrative examples in documents. You may use this\n",
      "    domain in literature without prior coordination or asking for permission.</p>\n",
      "    <p><a href=\"https://www.iana.org/domains/example\">More information...</a></p>\n",
      "</div>\n",
      "</body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('example.com.txt', 'r', encoding='utf-8') as f:\n",
    "    html = f.read()\n",
    "print(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "19h0ncnSxE0v"
   },
   "source": [
    "### re\n",
    "\n",
    "Давайте забудем, что HTML -- дерево, и попробуем попарсить его, как строчку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "wui5mmrFxE0w"
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "CqAserqlxE0y",
    "outputId": "7e142c02-7a6f-4030-e72f-bfe4b553f28c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<h1>Example Domain</h1>']\n",
      "['Example Domain']\n"
     ]
    }
   ],
   "source": [
    "h1 = re.findall(r'<h1>[\\w ]+</h1>', html)\n",
    "print(h1)\n",
    "h1 = re.findall(r'<h1>([\\w ]+)</h1>', html)\n",
    "print(h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "ATtuJReUxE0z",
    "outputId": "b581d3e3-a175-4781-98ed-07dfe12ff3f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<a href=\"https://www.iana.org/domains/example\">More information...</a>']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraphs = re.findall(r'<p>(.*)</p>', html)\n",
    "paragraphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tGuRp9XDxE00"
   },
   "source": [
    "Там же 2 параграфа, почему не нашёлся второй?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "3o_4zoTqxE00",
    "outputId": "99a9177a-5553-4d6b-9d9d-c2ec32bfaa42"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This domain is for use in illustrative examples in documents. You may use this\\n    domain in literature without prior coordination or asking for permission.</p>\\n    <p><a href=\"https://www.iana.org/domains/example\">More information...</a>']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraphs = re.findall(r'<p>([\\w\\W]*)</p>', html) \n",
    "paragraphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OU4Cyq4YxE01"
   },
   "source": [
    "Опять плохо.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "ymdswwohxE01",
    "outputId": "347b14ac-8371-4bd2-8502-4dc0ae0e83b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This domain is for use in illustrative examples in documents. You may use this\\n    domain in literature without prior coordination or asking for permission.',\n",
       " '<a href=\"https://www.iana.org/domains/example\">More information...</a>']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraphs = re.findall(r'<p>([\\w\\W]*?)</p>', html) # * - greedy; *? - lazy (non-greedy) \n",
    "paragraphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u2pUvS0XxE02"
   },
   "source": [
    "Жесть, да?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j-3m4_6KxE03"
   },
   "source": [
    "### lxml\n",
    "\n",
    "Воспользуемся библиотекой, которая знает про структуру XML (и HTML)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "4d-MqVk-xE04"
   },
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "from io import StringIO, BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "nVUgFdNMxE05",
    "outputId": "cf117974-7bb2-478c-c39e-69b3cce15e5b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lxml.etree._ElementTree at 0x28b1eefa680>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = etree.HTMLParser()\n",
    "tree = etree.parse(StringIO(html), parser)\n",
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "IFR3MT9kxE06",
    "outputId": "69c9b79c-eb04-4799-94d9-913ed442f3a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__copy__', '__deepcopy__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__ne__', '__new__', '__pyx_vtable__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '_setroot', 'docinfo', 'find', 'findall', 'findtext', 'getelementpath', 'getiterator', 'getpath', 'getroot', 'iter', 'iterfind', 'parse', 'parser', 'relaxng', 'write', 'write_c14n', 'xinclude', 'xmlschema', 'xpath', 'xslt']\n"
     ]
    }
   ],
   "source": [
    "print(dir(tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "n3dtDXBOxE06",
    "outputId": "d0340281-4a6c-4f5e-b3f5-4e06ad7f9f1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Element html at 0x28b1b648e80>\n",
      "b'<html>\\n<head>\\n    <title>Example Domain</title>\\n\\n    <meta charset=\"utf-8\">\\n    <meta http-equiv=\"Content-type\" content=\"text/html; charset=utf-8\">\\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\\n    <style type=\"text/css\">\\n    body {\\n        background-color: #f0f0f2;\\n        margin: 0;\\n        padding: 0;\\n        font-family: -apple-system, system-ui, BlinkMacSystemFont, \"Segoe UI\", \"Open Sans\", \"Helvetica Neue\", Helvetica, Arial, sans-serif;\\n        \\n    }\\n    div {\\n        width: 600px;\\n        margin: 5em auto;\\n        padding: 2em;\\n        background-color: #fdfdff;\\n        border-radius: 0.5em;\\n        box-shadow: 2px 3px 7px 2px rgba(0,0,0,0.02);\\n    }\\n    a:link, a:visited {\\n        color: #38488f;\\n        text-decoration: none;\\n    }\\n    @media (max-width: 700px) {\\n        div {\\n            margin: 0 auto;\\n            width: auto;\\n        }\\n    }\\n    </style>    \\n</head>\\n\\n<body>\\n<div>\\n    <h1>Example Domain</h1>\\n    <p>This domain is for use in illustrative examples in documents. You may use this\\n    domain in literature without prior coordination or asking for permission.</p>\\n    <p><a href=\"https://www.iana.org/domains/example\">More information...</a></p>\\n</div>\\n</body>\\n</html>\\n\\n'\n"
     ]
    }
   ],
   "source": [
    "print(tree.getroot())\n",
    "print(etree.tostring(tree.getroot(), pretty_print=True, method='html'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Kp8e8inoxE07",
    "outputId": "d7d3082c-efce-4643-bbea-b10a50436b2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This domain is for use in illustrative examples in documents. You may use this\n",
      "    domain in literature without prior coordination or asking for permission.\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "paragraphs = tree.xpath('//p')\n",
    "for p in paragraphs:\n",
    "    print(p.text)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "9di2iqxXxE07",
    "outputId": "9aa258fe-7a17-47ed-b202-0feeebddb04b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<p>This domain is for use in illustrative examples in documents. You may use this\\n    domain in literature without prior coordination or asking for permission.</p>\\n    <p><a href=\"https://www.iana.org/domains/example\">More information...</a></p>\\n</div>\\n</body>\\n</html>\\n\\n    \\n'\n",
      "b'<p><a href=\"https://www.iana.org/domains/example\">More information...</a></p>\\n</div>\\n</body>\\n</html>\\n\\n\\n'\n"
     ]
    }
   ],
   "source": [
    "for p in paragraphs:\n",
    "    print(etree.tostring(p, pretty_print=True, method='html'))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "goMSHz31xE08",
    "outputId": "558caf55-f988-4fcd-8f70-ad9f20169575"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "More information...\n",
      "{'href': 'https://www.iana.org/domains/example'}\n"
     ]
    }
   ],
   "source": [
    "hrefs = tree.xpath('//a')\n",
    "for href in hrefs:\n",
    "    print(href.text)  \n",
    "    print(href.attrib)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "FDGB3hvexE08",
    "outputId": "1409cf18-b4c1-4754-f3ae-1bb91aae8082"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Element a at 0x28b1ef04d40>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "specific_hrefs = tree.xpath('//a[@href=\"https://www.iana.org/domains/example\"]')\n",
    "specific_hrefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tT5VNOQZxE09"
   },
   "source": [
    "### BeautifulSoup\n",
    "\n",
    "Ещё один вариант, который хорошо подходит для парсинга HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "m4Nin8WbxE09",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "ejZpwbE7xE09"
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "kYVyzolBxE0-",
    "outputId": "8c85cd24-d8b2-40e3-f521-22adebbd4c77"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p>This domain is for use in illustrative examples in documents. You may use this\n",
       "     domain in literature without prior coordination or asking for permission.</p>,\n",
       " <p><a href=\"https://www.iana.org/domains/example\">More information...</a></p>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraphs = soup.find_all('p')\n",
    "paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "yAiKVtjvxE0-",
    "outputId": "a37ff175-486e-4df0-fa55-04121846e8b8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"https://www.iana.org/domains/example\">More information...</a>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hrefs = soup.find_all('a')\n",
    "hrefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "9SlKkDqexE0_",
    "outputId": "149cc753-eb8d-4835-dc86-4da687f2cedb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"https://www.iana.org/domains/example\">More information...</a>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hrefs = soup.find_all('a', href='https://www.iana.org/domains/example')\n",
    "hrefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "wjZ_OhrXxE0_",
    "outputId": "e32bd5ba-bd66-4b77-e9dc-e943d9ad9bf1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hrefs = soup.find_all('a', href='https://www.other-website.org/domains/example')\n",
    "hrefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "senc8j2UxE1B"
   },
   "source": [
    "## Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "7vmI1TK2xE1B",
    "outputId": "b2862c99-9584-46d8-8e17-6695e2b671d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.11 µs ± 1.1 µs per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "33.2 µs ± 2.36 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "17.7 µs ± 252 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit re.findall(r'<p>([\\w\\W]*?)</p>', html)\n",
    "%timeit tree.xpath('//p')\n",
    "%timeit soup.find_all('p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X9n3siCOxE1I"
   },
   "source": [
    "Мораль: regex -- это быстро.\n",
    "\n",
    "BeautifulSoup чуть дольше lxml, т.к. он для удобства работы преобразует документ в некий внутренний формат -- собственно, суп."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uKyEYwibxE1J"
   },
   "source": [
    "## Если осталось время и хочется совсем живой практики: scrapy\n",
    "\n",
    "Нужно минут 5-10, в зависимости от качества интернета.\n",
    "\n",
    "А заодно попрактикуемся в ipython magic!\n",
    "\n",
    "Будем парсить сайт с архивом курсов криптовалют: https://coinmarketcap.com/.\n",
    "\n",
    "Хочется открыть [historical snapshots](https://coinmarketcap.com/historical/) и для каждой недели выгрузить полную табличку.\n",
    "\n",
    "### Важно!\n",
    "\n",
    "Совершенно не обязательно понимать, что будет происходить дальше.\n",
    "\n",
    "Мораль: есть фреймворки, которые полностью берут на себя получение и парсинг HTML. \n",
    "\n",
    "А ещё они умеют распараллеливать процесс, вставлять случайные задержки (чтобы серверы не подумали, что вы робот и не заблокировали ваши запросы) и удобно экспортировать полученные данные (например, в базу данных). И многое другое. <br>И всё это контролируется `scrapy.cfg` -- одним конфигурационным файлом.\n",
    "\n",
    "Вам остаётся только указать, какие куски текста надо выцеплять. И в какую базу класть. Ну, почти. :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ikGw6vzexE1J"
   },
   "outputs": [],
   "source": [
    "import scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tlvHfzOqxE1K"
   },
   "outputs": [],
   "source": [
    "!rm -rf coinmarketcap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tpiWjIVSxE1L",
    "outputId": "aa866633-7834-4f79-ce78-fffe48369b66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Scrapy project 'coinmarketcap', using template directory '/home/zetman13/miniconda3/lib/python3.9/site-packages/scrapy/templates/project', created in:\r\n",
      "    /mnt/c/Users/Nick/Documents/coinmarketcap\r\n",
      "\r\n",
      "You can start your first spider with:\r\n",
      "    cd coinmarketcap\r\n",
      "    scrapy genspider example example.com\r\n"
     ]
    }
   ],
   "source": [
    "!scrapy startproject coinmarketcap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kSmTRgywxE1M"
   },
   "source": [
    "Что там внутри?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SFZQwjl8xE1N",
    "outputId": "7a1f9707-2ccb-4293-efe1-1436dd0f03fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".:\r\n",
      "coinmarketcap  scrapy.cfg\r\n",
      "\r\n",
      "./coinmarketcap:\r\n",
      "__init__.py  items.py  middlewares.py  pipelines.py  settings.py  spiders\r\n",
      "\r\n",
      "./coinmarketcap/spiders:\r\n",
      "__init__.py\r\n"
     ]
    }
   ],
   "source": [
    "!cd coinmarketcap; ls -R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FpKW3VmbxE1N"
   },
   "source": [
    "Специальная функция, чтобы из ноутбука формировать код в проекте scrapy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "84vZ_DL2xE1N"
   },
   "outputs": [],
   "source": [
    "def dump_to(path):\n",
    "    with open(path, 'w') as f:\n",
    "        f.write(_i)  # _i это \"последний выполненный Input\" в iPython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l5OmqoSnxE1O"
   },
   "source": [
    "### Внимание!\n",
    "\n",
    "Следующие ячейки не будут выполняться. <br>Мы просто помещаем код в Input, а потом перекладываем его в нужный файл."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mkCUb4VlxE1P"
   },
   "source": [
    "### Item: cперва определим, что хотим собирать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qgXSWhghxE1Q"
   },
   "outputs": [],
   "source": [
    "# -*- coding:utf8 -*-\n",
    "\n",
    "import scrapy\n",
    "\n",
    "\n",
    "class CurrencyItem(scrapy.Item):\n",
    "    date = scrapy.Field()\n",
    "    name = scrapy.Field()\n",
    "    symbol = scrapy.Field()\n",
    "    market_cap = scrapy.Field()\n",
    "    price = scrapy.Field()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pCHFpokTxE1R"
   },
   "outputs": [],
   "source": [
    "dump_to('./coinmarketcap/coinmarketcap/items.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uYxQ4GpsxE1R"
   },
   "source": [
    "### Spider: тот, кто собирает Item'ы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YP-xtJSTxE1R"
   },
   "outputs": [],
   "source": [
    "# -*- coding:utf8 -*-\n",
    "\n",
    "from scrapy import Request\n",
    "from scrapy.spiders import CrawlSpider, Rule\n",
    "from scrapy.linkextractors import LinkExtractor\n",
    "from scrapy.loader.processors import Join\n",
    "from scrapy.loader import ItemLoader\n",
    "from scrapy.selector import Selector\n",
    "from coinmarketcap.items import CurrencyItem\n",
    "\n",
    "class CurrencyLoader(ItemLoader):\n",
    "    pass\n",
    "\n",
    "class WeeklySpider(CrawlSpider):\n",
    "    name = 'weekly'\n",
    "    allowed_domains = ['coinmarketcap.com']\n",
    "    start_urls = ['https://coinmarketcap.com/historical/']\n",
    "    only_2018_april_regex = '/201904[0-9]{2}' # full history parsing takes ~4 hrs \n",
    "\n",
    "    rules = (\n",
    "        Rule(LinkExtractor(allow=(only_2018_april_regex, )), callback='parse_weekly_report', follow=False),\n",
    "    )\n",
    "\n",
    "    def parse_weekly_report(self, response):\n",
    "        \n",
    "        hxs = Selector(response)\n",
    "        items_html = hxs.xpath('//table//tr')\n",
    "        #print(len(items_html),type(items_html),dir(items_html))\n",
    "        #print(items_html)\n",
    "        items = []\n",
    "        \n",
    "        item_names = items_html.xpath('//td[@class=\"cmc-table__cell cmc-table__cell--sticky cmc-table__cell--sortable cmc-table__cell--left cmc-table__cell--sort-by__name\"]//div//a/text()').extract()\n",
    "        item_symbols = items_html.xpath('//td[@class=\"cmc-table__cell cmc-table__cell--sortable cmc-table__cell--left cmc-table__cell--sort-by__symbol\"]//div/text()').extract()\n",
    "        item_caps = items_html.xpath('//td[@class=\"cmc-table__cell cmc-table__cell--sortable cmc-table__cell--right cmc-table__cell--sort-by__market-cap\"]//p/text()').extract()\n",
    "        item_prices = items_html.xpath('//td[@class=\"cmc-table__cell cmc-table__cell--sortable cmc-table__cell--right cmc-table__cell--sort-by__price\"]//a/text()').extract()\n",
    "        print(response.request.url)\n",
    "        #print(len(item_prices),item_prices)\n",
    "        \n",
    "        for i in range(200):\n",
    "\n",
    "            item = CurrencyItem()\n",
    "            item['date'] = response.request.url.split('/')[-2]\n",
    "            item['name'] = item_names[i]\n",
    "            item['symbol'] = item_symbols[i]\n",
    "            item['market_cap'] = item_caps[i]\n",
    "            item['price'] = item_prices[i]\n",
    "\n",
    "            yield item\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xLUN4_f3xE1S"
   },
   "outputs": [],
   "source": [
    "dump_to('./coinmarketcap/coinmarketcap/spiders/weekly.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hl2-XdFAxE1S"
   },
   "source": [
    "### Pipeline: например, экспорт в БД\n",
    "\n",
    "Не бойтесь, про это будет отдельный семинар! (начиная с учебного года 2019-2020 - можно бояться)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cCPkKvSAxE1U"
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import os, logging\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy import create_engine, Table, Column, Integer, String, Date, MetaData, ForeignKey\n",
    "from sqlalchemy.engine.url import URL\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy.pool import NullPool\n",
    "from scrapy.exceptions import DropItem\n",
    "from scrapy import signals\n",
    "from coinmarketcap.items import CurrencyItem\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "DeclarativeBase = declarative_base()\n",
    "\n",
    "class Currency(DeclarativeBase):\n",
    "    __tablename__ = 'currency'\n",
    "    __table_args__ = {'sqlite_autoincrement': True}\n",
    "\n",
    "    id = Column('id', Integer, primary_key=True)\n",
    "    date = Column('date', Date)\n",
    "    name = Column('name', String)\n",
    "    symbol = Column('symbol', String)\n",
    "    market_cap = Column('market_cap', String)\n",
    "    price = Column('price', String)\n",
    "\n",
    "    def __init__(self, item):\n",
    "        self.date = pd.to_datetime(item['date'], format='%Y%m%d')\n",
    "        self.name = item['name']\n",
    "        self.symbol = item['symbol']\n",
    "        self.market_cap = item['market_cap']\n",
    "        self.price = item['price']\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"<Currency({0}, {1}, {2})>\".format(self.id, self.symbol, self.market_cap)\n",
    "\n",
    "\n",
    "class SqlitePipeline(object):\n",
    "    def __init__(self, settings):\n",
    "        self.database = settings.get('DATABASE')\n",
    "        self.sessions = {}\n",
    "\n",
    "    @classmethod\n",
    "    def from_crawler(cls, crawler):\n",
    "        pipeline = cls(crawler.settings)\n",
    "        crawler.signals.connect(pipeline.spider_closed, signals.spider_closed)\n",
    "        crawler.signals.connect(pipeline.spider_opened, signals.spider_opened)\n",
    "        return pipeline\n",
    "\n",
    "    def create_engine(self):\n",
    "        engine = create_engine(URL(**self.database), poolclass=NullPool)\n",
    "        return engine\n",
    "\n",
    "    def create_tables(self, engine):\n",
    "        DeclarativeBase.metadata.create_all(engine, checkfirst=True)\n",
    "\n",
    "    def create_session(self, engine):\n",
    "        session = sessionmaker(bind=engine)()\n",
    "        return session\n",
    "\n",
    "    def spider_opened(self, spider):\n",
    "        engine = self.create_engine()\n",
    "        self.create_tables(engine)\n",
    "        session = self.create_session(engine)\n",
    "        self.sessions[spider] = session\n",
    "\n",
    "    def spider_closed(self, spider):\n",
    "        session = self.sessions.pop(spider)\n",
    "        session.close()\n",
    "\n",
    "    def process_item(self, item, spider):\n",
    "        session = self.sessions[spider]\n",
    "        currency = Currency(item)\n",
    "        link_exists = session.query(Currency).filter_by(symbol=item['symbol'], date=item['date']).first() is not None\n",
    "        \n",
    "        if link_exists:\n",
    "            logger.info('Item {} is in db'.format(currency))\n",
    "            return item\n",
    "\n",
    "        try:\n",
    "            session.add(currency)\n",
    "            session.commit()\n",
    "            logger.info('Item {} stored in db'.format(currency))\n",
    "        except Exception as e:\n",
    "            logger.info('Failed to add {} to db'.format(currency))\n",
    "            session.rollback()\n",
    "            raise e\n",
    "\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LvAOH-CnxE1W"
   },
   "outputs": [],
   "source": [
    "dump_to('./coinmarketcap/coinmarketcap/pipelines.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yyETm9kIxE1Y"
   },
   "source": [
    "### Settings: общие настройки scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zIIGgZUGxE1Z"
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# Scrapy settings for coinmarketcap project\n",
    "#\n",
    "# For simplicity, this file contains only settings considered important or\n",
    "# commonly used. You can find more settings consulting the documentation:\n",
    "#\n",
    "#     https://doc.scrapy.org/en/latest/topics/settings.html\n",
    "#     https://doc.scrapy.org/en/latest/topics/downloader-middleware.html\n",
    "#     https://doc.scrapy.org/en/latest/topics/spider-middleware.html\n",
    "\n",
    "BOT_NAME = 'coinmarketcap'\n",
    "\n",
    "SPIDER_MODULES = ['coinmarketcap.spiders']\n",
    "NEWSPIDER_MODULE = 'coinmarketcap.spiders'\n",
    "\n",
    "DATABASE = {\n",
    "    'drivername': 'sqlite',\n",
    "    # 'host': 'localhost',\n",
    "    # 'port': '5432',\n",
    "    # 'username': 'YOUR_USERNAME',\n",
    "    # 'password': 'YOUR_PASSWORD',\n",
    "    'database': 'weekly.sqlite'\n",
    "}\n",
    "\n",
    "# Crawl responsibly by identifying yourself (and your website) on the user-agent\n",
    "USER_AGENT = '%s' % (BOT_NAME)\n",
    "\n",
    "# Obey robots.txt rules\n",
    "# ROBOTSTXT_OBEY = True\n",
    "\n",
    "# Configure maximum concurrent requests performed by Scrapy (default: 16)\n",
    "CONCURRENT_REQUESTS = 1\n",
    "\n",
    "# Configure a delay for requests for the same website (default: 0)\n",
    "# See https://doc.scrapy.org/en/latest/topics/settings.html#download-delay\n",
    "# See also autothrottle settings and docs\n",
    "#DOWNLOAD_DELAY = 3\n",
    "# The download delay setting will honor only one of:\n",
    "#CONCURRENT_REQUESTS_PER_DOMAIN = 16\n",
    "#CONCURRENT_REQUESTS_PER_IP = 16\n",
    "\n",
    "# Disable cookies (enabled by default)\n",
    "#COOKIES_ENABLED = False\n",
    "\n",
    "# Disable Telnet Console (enabled by default)\n",
    "#TELNETCONSOLE_ENABLED = False\n",
    "\n",
    "# Override the default request headers:\n",
    "#DEFAULT_REQUEST_HEADERS = {\n",
    "#   'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
    "#   'Accept-Language': 'en',\n",
    "#}\n",
    "\n",
    "# Enable or disable spider middlewares\n",
    "# See https://doc.scrapy.org/en/latest/topics/spider-middleware.html\n",
    "#SPIDER_MIDDLEWARES = {\n",
    "#    'coinmarketcap.middlewares.CoinmarketcapSpiderMiddleware': 543,\n",
    "#}\n",
    "\n",
    "# Enable or disable downloader middlewares\n",
    "# See https://doc.scrapy.org/en/latest/topics/downloader-middleware.html\n",
    "#DOWNLOADER_MIDDLEWARES = {\n",
    "#    'coinmarketcap.middlewares.CoinmarketcapDownloaderMiddleware': 543,\n",
    "#}\n",
    "\n",
    "# Enable or disable extensions\n",
    "# See https://doc.scrapy.org/en/latest/topics/extensions.html\n",
    "#EXTENSIONS = {\n",
    "#    'scrapy.extensions.telnet.TelnetConsole': None,\n",
    "#}\n",
    "\n",
    "# Configure item pipelines\n",
    "# See https://doc.scrapy.org/en/latest/topics/item-pipeline.html\n",
    "ITEM_PIPELINES = {\n",
    "   'coinmarketcap.pipelines.SqlitePipeline': 300,\n",
    "}\n",
    "\n",
    "# Enable and configure the AutoThrottle extension (disabled by default)\n",
    "# See https://doc.scrapy.org/en/latest/topics/autothrottle.html\n",
    "AUTOTHROTTLE_ENABLED = False\n",
    "# The initial download delay\n",
    "AUTOTHROTTLE_START_DELAY = 5\n",
    "# The maximum download delay to be set in case of high latencies\n",
    "AUTOTHROTTLE_MAX_DELAY = 60\n",
    "# The average number of requests Scrapy should be sending in parallel to\n",
    "# each remote server\n",
    "#AUTOTHROTTLE_TARGET_CONCURRENCY = 1.0\n",
    "# Enable showing throttling stats for every response received:\n",
    "#AUTOTHROTTLE_DEBUG = False\n",
    "\n",
    "# Enable and configure HTTP caching (disabled by default)\n",
    "# See https://doc.scrapy.org/en/latest/topics/downloader-middleware.html#httpcache-middleware-settings\n",
    "#HTTPCACHE_ENABLED = True\n",
    "#HTTPCACHE_EXPIRATION_SECS = 0\n",
    "#HTTPCACHE_DIR = 'httpcache'\n",
    "#HTTPCACHE_IGNORE_HTTP_CODES = []\n",
    "#HTTPCACHE_STORAGE = 'scrapy.extensions.httpcache.FilesystemCacheStorage'\n",
    "\n",
    "LOG_FILE = 'crawling.log'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IucYS9RmxE1a"
   },
   "outputs": [],
   "source": [
    "dump_to('./coinmarketcap/coinmarketcap/settings.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BZlybvdvxE1a"
   },
   "source": [
    "Посмотрим на структуру scrapy проекта ещё раз"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bhn-6BYPxE1c"
   },
   "outputs": [],
   "source": [
    "!cd coinmarketcap; ls -R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sMkGiiaRxE1c"
   },
   "source": [
    "### Всё! \n",
    "\n",
    "Запустим паука! \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aCCGFlm5xE1c"
   },
   "outputs": [],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "!cd coinmarketcap ; scrapy crawl weekly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4_PUXnznxE1e"
   },
   "source": [
    "Посмотрим, что получилось:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xwfndqKWxE1e"
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "connection = sqlite3.connect('./coinmarketcap/weekly.sqlite')\n",
    "\n",
    "df = pd.read_sql_query(\"SELECT * FROM currency\", connection)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qp-iYqJLxE1f"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
